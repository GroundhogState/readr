{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the statistics and uncertainty workshop at readr\n",
    "\n",
    "Since we'll be using them all day, let's import some scipy packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random variables\n",
    "\n",
    "## A Monte-Carlo method for simulating random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start working with random variables we need to build some computational models of them. Lets start by writing a function that generates samples from a given probability density function.\n",
    "\n",
    "We do this using rejection sampling. It involves generating random points in a given space and rejecting any that lie above our probability density function.\n",
    "\n",
    "Begin by writing a function that generates a random sample somewhere in the space (xmin<=x<xmax, ymin<=y<ymax). The returned point should be an array with the dimensions (2,)\n",
    "\n",
    "*hint: look up the documentation for numpy.random.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sample(xmin, xmax, ymin, ymax):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on a region of x in \\[-10,10) and y in \\[0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1000\n",
    "#Make an array called `samples' with dimensions (nsamples,2) and fill it with samples from the uniform distribution\n",
    "\n",
    "plt.scatter(samples[:,0],samples[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to generate one random sample from a given probability density function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_randv(pdf, xmin, xmax, ymin, ymax):\n",
    "    #Write a function that tests if a point from `samples' lies above the function `pdf'\n",
    "    # Have it return the x value if the point is below `pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a normal probability density function that has a variance of 1 and is centered at zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pdf = lambda x: #Write the Gaussian function here (don't normalise it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it!\n",
    "\n",
    "*Note the the build_samples function uses an area of [-10,10] by [0,1]. It's best to use PDFs that fill this space but don't go outside it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of random samples from the normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scipy does have a function in the stats package that generates samples from the normal distribution. We're doing it the hard way for fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions of random variables\n",
    "\n",
    "We can take functions of random variables just as we can for regular variables. Transforming a random variable  <b>X</b> through a function <b>f</b> will modify the probability density function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to apply the function <b>f=(X^2)</b> to a normal distribution and compare the result to what we 'derived' (found on Wikipedia) in the slides. You might need to play with the vertical scaling on the derived function to get it to overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YSamples = #Take the square of the array \n",
    "\n",
    "fYDerived = lambda x: #Write in the function that we derived in the slides\n",
    "    \n",
    "print('Mean: {}'.format(np.mean(YSamples)))\n",
    "print('Variance: {}'.format(np.var(YSamples)))\n",
    "\n",
    "nbins = 100\n",
    "\n",
    "xrange = np.arange(0.1,10,0.01)\n",
    "# Play around with the vertical scale to get the plots to overlap\n",
    "plt.plot(xrange, 14*nbins*fYDerived(xrange))\n",
    "\n",
    "plt.hist(YSamples, bins=nbins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear functions of random variables\n",
    "\n",
    "For linear functions, things aren't so bad. We can get a normally distributed random variable with any center point and variance by rescaling and shifting our distribution. Apply the function <b>f=m*X+b</b> to <b>X</b> with m=0.2 and b=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YSamples = #Apply the function f to an array containing normally distributed samples\n",
    "    \n",
    "print('Mean: {}'.format(np.mean(YSamples)))\n",
    "print('Variance: {}'.format(np.var(YSamples)))\n",
    "\n",
    "plt.hist(YSamples, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The central limit theorem\n",
    "\n",
    "Write a handful of different probability density functions that have a roughly zero mean and a variance on the order of ~1. Don't worry about normalisation, but keep them bounded by 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return #some probablity density function\n",
    "\n",
    "def f2(x):\n",
    "    return #some other probablity density function\n",
    "    \n",
    "def f3(x):\n",
    "    return #some other probablity density function\n",
    "\n",
    "def f4(x):\n",
    "    return #some other probablity density function\n",
    "    \n",
    "def f5(x):\n",
    "    return #some other probablity density function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "func = f1\n",
    "\n",
    "for i in range(10000):\n",
    "    samples.append(sample_randv(func, -10, 10, 0, 1))\n",
    "\n",
    "print('Mean: {}'.format(np.mean(samples)))\n",
    "print('Variance: {}'.format(np.var(samples)))\n",
    "\n",
    "plt.hist(samples, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if a random variable is a linear combination of different random variables? Let's see!\n",
    "\n",
    "We'll make sample sets from 20 different random variables by multiplying our probability density functions with random scaling factors. We can then take the element-wise mean of the sample sets to get a new derived distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try generating sets of samples that consist of sums of samples from a set of distributions\n",
    "# Play around with different weights, different pdfs, as well as taking samples from the same pdf\n",
    "# Plot what you get!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
